---
title: "Main"
author: "Vikas, Sean, Boxuan Zhao, Xuehan Liu"
date: "4/26/2017"
output: pdf_document
---

###Introduction
In this project, we look at auction items' price on sotheby's.com and try to predict the actual auction price based on some features provided in the websites, including genre, period the painting generated, as well as features from images. 

```{r}
setwd("/Users/xuehan/Desktop/Spr2017-proj5-grp8/doc") #change to your local path
```


###Step 1: Pull data from sotheby's (Sean)



###Step 2: Feature clean up and extractions 
We scrpaed information from Sotheby's website and the initial features we have from the csv file are the following:

"auctionDate","auctionId","auctionName","currency","genre", "guaranteeLine","highEst","id","isSold","lowEst","medium","salePrice","title","type", "auctionYear", "lot_desc"

We created categorical variables(1s and 0s) History, Portrait, Landscape, Genre, StillLife, Abstract, and Other from the column "type", in which we utilized regrular expressions to extract type for each paintings.

In addition, we also created diff variable, which is estimated by the increased proportion from highEst and lowEst.

More categorical variables, famous and sold, which record whether each painting is owned by famous people and whether it is sold, based on the information we extract from lot_desc and isSold.

At last, we extract the height and width of the paintings from the lot_desc and form the final two features from our data set.

In addition to the csv file, we have also created HOG feature as well as RGB feature from the paintings. 

####Step 2a: Data clean-up and feature extraction
```{r}
source("../lib/FeatureConstruction.R")
my.dat = read.csv("../data/auctionItems.csv",header = TRUE, stringsAsFactors = FALSE)
feature.csv = Feature.Construction(my.dat)#Construct the first type of features
#dim(feature.csv)
animal<-read.csv("../output/AnimalFeature.csv")
colnames(animal)<-c("ID","animal")

#Rename ID for each observations in the dataset
img_dir_full <- "/Users/xuehan/Desktop/Images/" #local path of 3000 images
file.names <- list.files(img_dir_full,pattern="*.jpg") 
file.names.short<-NULL
for (i in 1:length(file.names)){
  file.names.short[i]<-substr(file.names[[i]],1,nchar(file.names[[i]])-4)
}

for (i in 1:nrow(animal)){
  animal$ID[i]<-file.names.short[i]
}

#Merge two datasets
data.full1<-merge(feature.csv,animal,by.x="ID",by.y="ID")
```

####Step 2b: Images feature extraction 
In this step, I extracted HoG feature, RGB feature and VGG feature from the images that associate with each auction item. Since most of our observations are paintings, it makes sense that we extract information from those paintings directly. 

```{r}
source(../lib/image_feature_extraction.R)#run this first

#If the above function took too long to run (3000 images), you can manually run rgb_seperate.R under doc folder. It generates the whole 3000 by 512 matrix in four chuncks, meaning from the 1th to 500th, 501th to 1000th and so on.


###HoG Feature

setwd("/Users/xuehan/Desktop/Spr2017-proj5-grp8/doc")
HoG<-read.csv("../data/HoG.csv",header=T)[,-1]
head(HoG)


###RGB Feature
RGB<-read.csv("../data/RGB.csv",header=T)[,-1]
head(RGB)


###VGG Feature


```

####Step 2c: Merge all sub-datasets that contain features together to generate a functional dataset with full features for model fitting.

```{r}
#Merge datasets by paintings' ID which is the last column
head(HoG[,ncol(HoG)])
colnames(HoG)[ncol(HoG)]<-"ID"
head(RGB[,ncol(RGB)])
colnames(RGB)[ncol(RGB)]<-"ID"

data.full<-merge(HoG,RGB,by.x="ID",by.y="ID")
colnames(data.full)[2:55]<-paste("HoG",1:54,sep="")
colnames(data.full)[56:567]<-paste("RGB",1:512,sep="")
#store full data
data_full<-merge(data.full,data.full1,by.x="ID",by.y="ID" )
write.csv(data_full,file="../data/data_full.csv")
```


###Step 3: Fit the model and find those important features in order to predict auction price
```{r}
#read in the cleaned up data
data_full<-read.csv("../data/data_full.csv")
```

###Conclusion


